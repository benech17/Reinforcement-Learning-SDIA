{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6378dcd6-9bb7-48d1-a095-7727a24b7173",
      "metadata": {
        "id": "6378dcd6-9bb7-48d1-a095-7727a24b7173"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "- Follow the installation instructions in the readme file\n",
        "- Answer the questions in this notebook\n",
        "- Once your work is finished: restart the kernel, run all cells in order and check that the outputs are correct.\n",
        "- Send your completed notebook to `remy.degenne@inria.fr` with email title `SL_TP4_NAME1_NAME2` (or `SL_TP4_NAME` if you work alone).\n",
        "\n",
        "**Deadline: January 23, 15:00 CET**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "9e22d328",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e22d328",
        "outputId": "3c806856-8ebd-4ffa-fc37-aef8042bd3fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing packages, please wait a few moments. Restart the runtime after the installation.\n",
            "Collecting git+https://github.com/rlberry-py/rlberry\n",
            "  Cloning https://github.com/rlberry-py/rlberry to /tmp/pip-req-build-ynq78h7z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/rlberry-py/rlberry /tmp/pip-req-build-ynq78h7z\n",
            "  Resolved https://github.com/rlberry-py/rlberry to commit ad3febee482cd7fa5ae15b3e37081d6d6451ee9e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn) (3.2.0)\n",
            "Requirement already satisfied: dill<0.4.0,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from rlberry==0.5.0.post29.dev0+2b871b8) (0.3.7)\n",
            "Requirement already satisfied: docopt<0.7.0,>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from rlberry==0.5.0.post29.dev0+2b871b8) (0.6.2)\n",
            "Requirement already satisfied: gymnasium[accept-rom-license,atari]<0.30.0,>=0.29.1 in /usr/local/lib/python3.10/dist-packages (from rlberry==0.5.0.post29.dev0+2b871b8) (0.29.1)\n",
            "Requirement already satisfied: moviepy<2.0.0,>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from rlberry==0.5.0.post29.dev0+2b871b8) (1.0.3)\n",
            "Requirement already satisfied: pandas==2.1.0 in /usr/local/lib/python3.10/dist-packages (from rlberry==0.5.0.post29.dev0+2b871b8) (2.1.0)\n",
            "Requirement already satisfied: pygame-ce<3.0.0,>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from rlberry==0.5.0.post29.dev0+2b871b8) (2.4.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from rlberry==0.5.0.post29.dev0+2b871b8) (6.0.1)\n",
            "Requirement already satisfied: seaborn==0.12.2 in /usr/local/lib/python3.10/dist-packages (from rlberry==0.5.0.post29.dev0+2b871b8) (0.12.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from rlberry==0.5.0.post29.dev0+2b871b8) (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.0->rlberry==0.5.0.post29.dev0+2b871b8) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.0->rlberry==0.5.0.post29.dev0+2b871b8) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.1.0->rlberry==0.5.0.post29.dev0+2b871b8) (2023.4)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn==0.12.2->rlberry==0.5.0.post29.dev0+2b871b8) (3.7.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]<0.30.0,>=0.29.1->rlberry==0.5.0.post29.dev0+2b871b8) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]<0.30.0,>=0.29.1->rlberry==0.5.0.post29.dev0+2b871b8) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]<0.30.0,>=0.29.1->rlberry==0.5.0.post29.dev0+2b871b8) (0.0.4)\n",
            "Requirement already satisfied: shimmy[atari]<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]<0.30.0,>=0.29.1->rlberry==0.5.0.post29.dev0+2b871b8) (0.2.1)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]<0.30.0,>=0.29.1->rlberry==0.5.0.post29.dev0+2b871b8) (0.4.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy<2.0.0,>=1.0.3->rlberry==0.5.0.post29.dev0+2b871b8) (4.4.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy<2.0.0,>=1.0.3->rlberry==0.5.0.post29.dev0+2b871b8) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy<2.0.0,>=1.0.3->rlberry==0.5.0.post29.dev0+2b871b8) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy<2.0.0,>=1.0.3->rlberry==0.5.0.post29.dev0+2b871b8) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy<2.0.0,>=1.0.3->rlberry==0.5.0.post29.dev0+2b871b8) (0.4.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]<0.30.0,>=0.29.1->rlberry==0.5.0.post29.dev0+2b871b8) (8.1.7)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]<0.30.0,>=0.29.1->rlberry==0.5.0.post29.dev0+2b871b8) (0.6.1)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy<2.0.0,>=1.0.3->rlberry==0.5.0.post29.dev0+2b871b8) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy<2.0.0,>=1.0.3->rlberry==0.5.0.post29.dev0+2b871b8) (67.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.2->rlberry==0.5.0.post29.dev0+2b871b8) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.2->rlberry==0.5.0.post29.dev0+2b871b8) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.2->rlberry==0.5.0.post29.dev0+2b871b8) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.2->rlberry==0.5.0.post29.dev0+2b871b8) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.2->rlberry==0.5.0.post29.dev0+2b871b8) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn==0.12.2->rlberry==0.5.0.post29.dev0+2b871b8) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.1.0->rlberry==0.5.0.post29.dev0+2b871b8) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy<2.0.0,>=1.0.3->rlberry==0.5.0.post29.dev0+2b871b8) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy<2.0.0,>=1.0.3->rlberry==0.5.0.post29.dev0+2b871b8) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy<2.0.0,>=1.0.3->rlberry==0.5.0.post29.dev0+2b871b8) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy<2.0.0,>=1.0.3->rlberry==0.5.0.post29.dev0+2b871b8) (2023.11.17)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari]<0.30.0,>=0.29.1->rlberry==0.5.0.post29.dev0+2b871b8) (0.8.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari]<0.30.0,>=0.29.1->rlberry==0.5.0.post29.dev0+2b871b8) (6.1.1)\n"
          ]
        }
      ],
      "source": [
        "# This cell is setting up google colab. Ignore it if you work locally.\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    print(\"Installing packages, please wait a few moments. Restart the runtime after the installation.\")\n",
        "    # install rlberry library\n",
        "    !pip install scipy scikit_learn git+https://github.com/rlberry-py/rlberry"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aef0b14a-6e93-4f0b-be94-84d090c5d184",
      "metadata": {
        "id": "aef0b14a-6e93-4f0b-be94-84d090c5d184"
      },
      "source": [
        "# Fitted Q Iteration (FQI)\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, you will implement the Fitted Q Iteration algorithm (FQI) to solve the [CartPole](https://gymnasium.farama.org/environments/classic_control/cart_pole/) problem.\n",
        "\n",
        "This notebooks will first cover the basics for using the Gymnasium library: how to instantiate an environment, step into it and collect training data from the FQI algorithm.\n",
        "\n",
        "You will then learn how to implement step-by-step the FQI algorithm which is the predecessor of the [Deep Q-Network (DQN)](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html) algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "008852aa-cf8f-4c81-afaf-7d3be75f389d",
      "metadata": {
        "id": "008852aa-cf8f-4c81-afaf-7d3be75f389d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import os\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.base import RegressorMixin\n",
        "from sklearn.exceptions import NotFittedError\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.neighbors import KNeighborsRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2369b55-266c-4dbe-b14d-250ef7386407",
      "metadata": {
        "id": "e2369b55-266c-4dbe-b14d-250ef7386407"
      },
      "source": [
        "## First steps with the Gym interface\n",
        "\n",
        "An environment that follows the [gym interface](https://gymnasium.farama.org/) is quite simple to use.\n",
        "It provides to this user mainly three methods, which have the following signature (for gym versions > 0.26):\n",
        "\n",
        "- `reset()` called at the beginning of an episode, it returns an observation and a dictionary with additional info (defaults to an empty dict)\n",
        "- `step(action)` called to take an action with the environment, it returns the next observation, the immediate reward, whether new state is a terminal state (episode is finished), whether the max number of timesteps is reached (episode is artificially finished), and additional information\n",
        "- (Optional) `render()` which allow to visualize the agent in action. Note that graphical interface does not work on google colab, so we cannot use it directly (we have to rely on `render_mode='rbg_array'` to retrieve an image of the scene).\n",
        "\n",
        "Under the hood, it also contains two useful properties:\n",
        "- `observation_space` which is one of the gym spaces (`Discrete`, `Box`, ...) and describe the type and shape of the observation\n",
        "- `action_space` which is also a gym space object that describes the action space, so the type of action that can be taken\n",
        "\n",
        "The best way to learn about [gym spaces](https://gymnasium.farama.org/api/spaces/) is to look at the [source code](https://github.com/Farama-Foundation/Gymnasium/tree/main/gymnasium/spaces), but you need to know at least the main ones:\n",
        "- `gym.spaces.Box`: A (possibly unbounded) box in $R^n$. Specifically, a Box represents the Cartesian product of n closed intervals. Each interval has the form of one of $[a, b]$, $(-\\infty, b]$, $[a, \\infty)$, or $(-\\infty, \\infty)$. Example: A 1D-Vector or an image observation can be described with the Box space.\n",
        "```python\n",
        "# Example for using image as input:\n",
        "observation_space = spaces.Box(low=0, high=255, shape=(HEIGHT, WIDTH, N_CHANNELS), dtype=np.uint8)\n",
        "```                                       \n",
        "\n",
        "- `gym.spaces.Discrete`: A discrete space in $\\{ 0, 1, \\dots, n-1 \\}$\n",
        "  Example: if you have two actions (\"left\" and \"right\") you can represent your action space using `Discrete(2)`, the first action will be 0 and the second 1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af049724-3db9-4dec-a40c-3aa025735f00",
      "metadata": {
        "id": "af049724-3db9-4dec-a40c-3aa025735f00"
      },
      "source": [
        "## CartPole Environment\n",
        "\n",
        "For this example, we will use CartPole environment, a classic control problem.\n",
        "\n",
        "\"A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright. \"\n",
        "\n",
        "Cartpole environment: [https://gymnasium.farama.org/environments/classic_control/cart_pole/](https://gymnasium.farama.org/environments/classic_control/cart_pole/)\n",
        "\n",
        "![Cartpole](https://cdn-images-1.medium.com/max/1143/1*h4WTQNVIsvMXJTCpXm_TAw.gif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "60ec422f-2edd-40df-8da2-c1093e1da38c",
      "metadata": {
        "id": "60ec422f-2edd-40df-8da2-c1093e1da38c"
      },
      "outputs": [],
      "source": [
        "# Instantiate the environment\n",
        "env = gym.make(\"CartPole-v1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "476f88b6-4fe2-45ec-bddd-4d83feb3a86f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "476f88b6-4fe2-45ec-bddd-4d83feb3a86f",
        "outputId": "747c01d4-0027-45a1-8f14-0808567f5540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observation space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
            "Shape: (4,)\n",
            "Action space: Discrete(2)\n"
          ]
        }
      ],
      "source": [
        "# Box(4,) means that it is a Vector with 4 components\n",
        "print(\"Observation space:\", env.observation_space)\n",
        "print(\"Shape:\", env.observation_space.shape)\n",
        "\n",
        "# Discrete(2) means that there is two discrete actions\n",
        "print(\"Action space:\", env.action_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "e414990e-2cbd-4f6f-b268-42f16a9b253b",
      "metadata": {
        "id": "e414990e-2cbd-4f6f-b268-42f16a9b253b"
      },
      "outputs": [],
      "source": [
        "# The reset method is called at the beginning of an episode\n",
        "obs, info = env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "e89a95c8-d64a-43a3-adee-344891bbd1b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e89a95c8-d64a-43a3-adee-344891bbd1b7",
        "outputId": "b620c9e6-a202-49a6-ac48-2046615ad341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled action: 0\n"
          ]
        }
      ],
      "source": [
        "# Sample a random action\n",
        "action = env.action_space.sample()\n",
        "print(f\"Sampled action: {action}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "311777a2-9518-496a-b1e8-0eb1af81fb7d",
      "metadata": {
        "id": "311777a2-9518-496a-b1e8-0eb1af81fb7d"
      },
      "outputs": [],
      "source": [
        "# step in the environment\n",
        "obs, reward, terminated, truncated, info = env.step(action)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "5102a9c8-8407-4f88-b58d-4e3e5a00af3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5102a9c8-8407-4f88-b58d-4e3e5a00af3b",
        "outputId": "12293f29-250d-4973-cf8d-bd8bd2e54584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4,) 1.0 False False {}\n"
          ]
        }
      ],
      "source": [
        "# Note the obs is a numpy array\n",
        "# info is an empty dict for now but can contain any debugging info\n",
        "# reward is a scalar\n",
        "print(obs.shape, reward, terminated, truncated, info)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90fbec50-1da0-4bc4-8b88-79fa38480bfe",
      "metadata": {
        "id": "90fbec50-1da0-4bc4-8b88-79fa38480bfe"
      },
      "source": [
        "### Exercise: write the function to collect data\n",
        "\n",
        "This function collects a dataset of transitions that will be used to train a model using the FQI algorithm.\n",
        "\n",
        "See docstring of the function for what is expected as input/output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "1f1b3ff1-911b-4582-91f7-49420380eda3",
      "metadata": {
        "id": "1f1b3ff1-911b-4582-91f7-49420380eda3"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class OfflineData:\n",
        "    \"\"\"\n",
        "    A class to store transitions.\n",
        "    \"\"\"\n",
        "\n",
        "    observations: np.ndarray  # same as \"state\" in the theory\n",
        "    next_observations: np.ndarray\n",
        "    actions: np.ndarray\n",
        "    rewards: np.ndarray\n",
        "    terminateds: np.ndarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "f9f753ed-5f5d-4133-ab82-c84b3cfe2eef",
      "metadata": {
        "id": "f9f753ed-5f5d-4133-ab82-c84b3cfe2eef"
      },
      "outputs": [],
      "source": [
        "def collect_data(env: gym.Env, n_steps: int = 50_000) -> OfflineData:\n",
        "    \"\"\"\n",
        "    Collect transitions using a random agent (sample action randomly).\n",
        "\n",
        "    :param env: The environment.\n",
        "    :param n_steps: Number of steps to perform in the env.\n",
        "    :return: The collected transitions.\n",
        "    \"\"\"\n",
        "\n",
        "    assert isinstance(env.observation_space, spaces.Box)\n",
        "    # Numpy arrays (buffers) to collect the data\n",
        "    observations = np.zeros((n_steps, *env.observation_space.shape))\n",
        "    next_observations = np.zeros((n_steps, *env.observation_space.shape))\n",
        "    # Discrete actions\n",
        "    actions = np.zeros((n_steps, 1))\n",
        "    rewards = np.zeros((n_steps,))\n",
        "    terminateds = np.zeros((n_steps,))\n",
        "\n",
        "    # Variable to know if the episode is over (done = terminated or truncated)\n",
        "    done = False\n",
        "    # Start the first episode\n",
        "    obs, _ = env.reset()\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "    # You need to collect transitions for `n_steps` using\n",
        "    # a random agent (sample action uniformly).\n",
        "    # Do not forget to reset the environment if the current episode is over\n",
        "    # (done = terminated or truncated)\n",
        "    # 1. Sample a random action\n",
        "    # 2. Step in the env using this random action\n",
        "    # 3. Retrieve the new transition data (observation, reward, ...)\n",
        "    #  and update the numpy arrays (buffers)\n",
        "    # 4. Repeat until you collected `n_steps` transitions\n",
        "    for i in range(n_steps):\n",
        "        action = env.action_space.sample() # we sample a random action\n",
        "        next_obs, reward, terminated, truncated, _ = env.step(action) # we step in the env using this random action\n",
        "\n",
        "        #we update the numpy arrays\n",
        "        observations[i] = obs \n",
        "        next_observations[i] = next_obs \n",
        "        actions[i] = action \n",
        "        rewards[i] = reward \n",
        "        terminateds[i] = terminated or truncated # we update the variable done to know if the episode is over\n",
        "\n",
        "        obs = next_obs\n",
        "\n",
        "        if terminated or truncated: # if the episode is over, we reset the environment\n",
        "            obs, _ = env.reset()\n",
        "\n",
        "    ### END OF YOUR CODE\n",
        "\n",
        "    return OfflineData(\n",
        "        observations,\n",
        "        next_observations,\n",
        "        actions,\n",
        "        rewards,\n",
        "        terminateds,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbe5d4b3-d3d6-4f82-9337-a8566c1fc707",
      "metadata": {
        "id": "dbe5d4b3-d3d6-4f82-9337-a8566c1fc707"
      },
      "source": [
        "Let's try the collect data method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "f499a940-a35f-4b8c-86bb-94231c41a87e",
      "metadata": {
        "id": "f499a940-a35f-4b8c-86bb-94231c41a87e"
      },
      "outputs": [],
      "source": [
        "env_id = \"CartPole-v1\"\n",
        "env = gym.make(env_id)\n",
        "n_steps = 10_000\n",
        "# Collect transitions for n_steps\n",
        "data = collect_data(env=env, n_steps=n_steps)\n",
        "# Check the length of the collected data\n",
        "assert len(data.observations) == n_steps\n",
        "assert len(data.actions) == n_steps\n",
        "# Check that there are multiple episodes in the data\n",
        "assert not np.all(data.terminateds)\n",
        "assert np.any(data.terminateds)\n",
        "# Check the shape of the collected data\n",
        "if env_id == \"CartPole-v1\":\n",
        "    assert data.observations.shape == (n_steps, 4)\n",
        "    assert data.next_observations.shape == (n_steps, 4)\n",
        "assert data.actions.shape == (n_steps, 1)\n",
        "assert data.rewards.shape == (n_steps,)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "239ad0de-bec9-4918-a691-4322d062c45a",
      "metadata": {
        "id": "239ad0de-bec9-4918-a691-4322d062c45a"
      },
      "source": [
        "## Fitted Q Iteration (FQI) Agent\n",
        "\n",
        "See Lecture 4, slide 31 (and next slides for more explanations in the linear case, although this practical session is not linear).\n",
        "\n",
        "At each iteration of the algorithm, a dataset of transitions is gathered. Then target Q values for each transition are computed and the algorithm solves a regression problem with the transitions as inputs and the target values as outputs to update its Q-value approximation.\n",
        "\n",
        "After the maximal number of iterations is reached, the policy returned is the greedy policy with respect to the current Q-values.\n",
        "\n",
        "### Choosing a regression model\n",
        "\n",
        "With FQI, you can use any regression model to produce a Q-value estimator from a dataset of transitions and targets.\n",
        "\n",
        "Here we are choosing a [k-nearest neighbors regressor](https://scikit-learn.org/stable/modules/neighbors.html#regression), but one could choose a linear model, a decision tree, a neural network, ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "1d8d873e-bc40-4a35-b98b-4fe9ce916aab",
      "metadata": {
        "id": "1d8d873e-bc40-4a35-b98b-4fe9ce916aab"
      },
      "outputs": [],
      "source": [
        "# First choose the regressor\n",
        "model_class = partial(\n",
        "    KNeighborsRegressor, n_neighbors=30\n",
        ")  # LinearRegression, GradientBoostingRegressor..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bf9544c-87f4-4872-9ae9-eef49c3a040a",
      "metadata": {
        "id": "5bf9544c-87f4-4872-9ae9-eef49c3a040a"
      },
      "source": [
        "### 1. Exercise: write the function to predict Q-Values\n",
        "\n",
        "In FQI, we will need to compute, for any transition $(s, a, r, s')$, a target value $y = r + \\gamma \\cdot \\max_{a' \\in A}(Q^{n-1}_\\theta(s', a'))$. In order to do that, we need to be able to compute the current Q-value of state-action pairs.\n",
        "\n",
        "See docstring of the function for what is expected as input/output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "38316a3a",
      "metadata": {
        "id": "38316a3a"
      },
      "outputs": [],
      "source": [
        "def get_q_values(\n",
        "    model: RegressorMixin,\n",
        "    obs: np.ndarray,\n",
        "    n_actions: int,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Retrieve the q-values for a set of observations obs.\n",
        "    Q(s, action) for all s in obs and all possible actions.\n",
        "\n",
        "    :param model: Q-value estimator\n",
        "    :param obs: A batch of observations\n",
        "    :param n_actions: Number of discrete actions.\n",
        "    :return: The predicted q-values for the given observations\n",
        "        (batch_size, n_actions)\n",
        "    \"\"\"\n",
        "    batch_size = len(obs)\n",
        "    q_values = np.zeros((batch_size, n_actions))\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "    # for every possible actions a:\n",
        "    # 1. Create the regression model input $(s, a)$ for the action a\n",
        "    # and states s (here a batch of observations)\n",
        "    # 2. Predict the q-values for the batch of states (use model.predict)\n",
        "    # 3. Update q-values array for the current action a\n",
        "    for a in range(n_actions):\n",
        "        model_input = np.concatenate((obs, np.ones((batch_size, 1)) * a), axis=1) # we create the regression model input\n",
        "        q_values[:, a] = model.predict(model_input) # we predict the q-values for the batch of states and update q-values array for the current action a\n",
        "\n",
        "\n",
        "\n",
        "    ### END OF YOUR CODE\n",
        "\n",
        "    return q_values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be7a24b4-a416-4607-af3a-9dfdbc203fc1",
      "metadata": {
        "id": "be7a24b4-a416-4607-af3a-9dfdbc203fc1"
      },
      "source": [
        "### Create the Agent\n",
        "To create an agent, rlberry requires to use a **very simple interface**, with basically two methods to implement: `fit()` and `eval()`.\n",
        "\n",
        "You can find more information on this interface [here(AgentWithSimplePolicy)](rlberry.agents.agent.AgentWithSimplePolicy).\n",
        "### function fit() :\n",
        "\n",
        "#### 1. First Iteration\n",
        "\n",
        "For $n = 0$, the initial training set is defined as:\n",
        "\n",
        "- $x = (s_t, a_t)$\n",
        "- $y = r_t$\n",
        "\n",
        "We fit a regression model $f_\\theta(x) = y$ to obtain $ Q^{n=0}_\\theta(s, a) $\n",
        "\n",
        "\n",
        "\n",
        "#### 2. Exercise: the fitted Q iterations\n",
        "\n",
        "1. Create the training set based on the previous iteration $ Q^{n-1}_\\theta(s, a) $ and the transitions:\n",
        "- input: $x = (s_t, a_t)$\n",
        "- if $s_{t+1}$ is non-terminal: $y = r_t + \\gamma \\cdot \\max_{a' \\in A}(Q^{n-1}_\\theta(s_{t+1}, a'))$\n",
        "- if $s_{t+1}$ is terminal, do not bootstrap: $y = r_t$\n",
        "\n",
        "2. Fit a model $f_\\theta$ using a regression algorithm to obtain $ Q^{n}_\\theta(s, a)$\n",
        "\n",
        "\\begin{aligned}\n",
        " f_\\theta(x) = y\n",
        "\\end{aligned}\n",
        "\n",
        "4. Repeat, $n = n + 1$\n",
        "\n",
        "### function evaluate() :\n",
        "\n",
        "#### 3. Exercise: write the function to evaluate a model\n",
        "\n",
        "A greedy policy $\\pi(s)$ can be defined using the q-value:\n",
        "\n",
        "$\\pi(s) = argmax_{a \\in A} Q(s, a)$.\n",
        "\n",
        "It is the policy that take the action with the highest q-value for a given state.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "1fe29bd2-ea95-4778-b466-537a088615b0",
      "metadata": {
        "id": "1fe29bd2-ea95-4778-b466-537a088615b0"
      },
      "outputs": [],
      "source": [
        "from rlberry.agents import Agent\n",
        "from gymnasium.wrappers.monitoring.video_recorder import VideoRecorder\n",
        "\n",
        "\n",
        "class Fitted_Q_Iteration(Agent):\n",
        "    name = \"Fitted_Q_Iteration\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        env,\n",
        "        model_class,\n",
        "        n_steps_collection=50_000,  # Number of steps to perform in the env to collect data.\n",
        "        eval_freq=2,\n",
        "        n_eval_episodes=10,\n",
        "        gamma=0.99,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        # it's important to put **kwargs to ensure compatibility with the base class\n",
        "        # self.env is initialized here\n",
        "        super().__init__(env=env, **kwargs)\n",
        "\n",
        "        self.model_class = model_class  # The Agent's regression model class\n",
        "        self.eval_freq = eval_freq  # How often do we evaluate the learned model\n",
        "        self.n_eval_episodes = n_eval_episodes  # How many episodes to evaluate every eval-freq\n",
        "\n",
        "        self.gamma = 0.99  # discount factor\n",
        "        self.n_actions = int(self.env.action_space.n)  # Number of discrete actions\n",
        "\n",
        "        # Collect data : transitions for n_steps\n",
        "        self.current_data = collect_data(env=self.env, n_steps=n_steps_collection)\n",
        "\n",
        "        # 1 - First iteration:\n",
        "        # The target q-value is the reward obtained\n",
        "        targets = self.current_data.rewards.copy()\n",
        "        # Create input for current observations and actions\n",
        "        # Concatenate the observations and actions\n",
        "        # so we can predict qf(s_t, a_t)\n",
        "        self.current_obs_input = np.concatenate(\n",
        "            (self.current_data.observations, self.current_data.actions), axis=1\n",
        "        )\n",
        "        # Fit the estimator for the current target\n",
        "        self.current_model = model_class().fit(self.current_obs_input, targets)\n",
        "\n",
        "    def fit(self, budget, **kwargs):\n",
        "        # 2 - the fitted Q iterations\n",
        "        for iter_idx in range(budget):\n",
        "            ### YOUR CODE HERE\n",
        "            # TODO:\n",
        "            # 1. Compute the q values for the next states using\n",
        "            # the previous regression model\n",
        "            # 2. Keep only the next q values that correspond\n",
        "            # to the greedy-policy\n",
        "            # 3. Construct the regression target (TD(0) target)\n",
        "            # 4. Fit a new regression model with this new target\n",
        "\n",
        "            next_q_values = get_q_values(self.current_model, self.current_data.next_observations, self.n_actions)\n",
        "\n",
        "            # Select max Q-value for each next observation\n",
        "            max_next_q_values = np.max(next_q_values, axis=1)\n",
        "\n",
        "            # Construct TD(0) target\n",
        "            targets = self.current_data.rewards + self.gamma * max_next_q_values * (1 - self.current_data.terminateds)\n",
        "\n",
        "            # Fit new regression model\n",
        "            self.current_model = self.model_class().fit(self.current_obs_input, targets)\n",
        "\n",
        "\n",
        "            ### END OF YOUR CODE\n",
        "\n",
        "            if (iter_idx + 1) % self.eval_freq == 0:\n",
        "                print(f\"Iter {iter_idx + 1}\")\n",
        "                print(\n",
        "                    f\"Score: {self.current_model.score(self.current_obs_input, targets):.2f}\"\n",
        "                )\n",
        "                final_eval_result = self.eval(self.n_eval_episodes)\n",
        "\n",
        "        info = {\"final_eval_result\": final_eval_result}\n",
        "        return info  # return the final eval mean, but more informations are directly displayed by the eval() function in the output terminal.\n",
        "\n",
        "    # 3 - function to evaluate a model\n",
        "    def eval(\n",
        "        self,\n",
        "        n_simulations: int = 10,\n",
        "        video_name: Optional[str] = None,\n",
        "    ) -> None:\n",
        "        episode_returns, episode_reward = [], 0.0\n",
        "        total_episodes = 0\n",
        "        done = False\n",
        "\n",
        "        if not self.eval_env:\n",
        "            self.eval_env = self.env\n",
        "\n",
        "        # Setup video recorder\n",
        "        video_recorder = None\n",
        "        if video_name is not None and self.eval_env.render_mode == \"rgb_array\":\n",
        "            os.makedirs(\"./logs/videos/\", exist_ok=True)\n",
        "\n",
        "            video_recorder = VideoRecorder(\n",
        "                env=self.eval_env,\n",
        "                base_path=f\"./logs/videos/{video_name}\",\n",
        "            )\n",
        "\n",
        "        obs, _ = self.eval_env.reset()\n",
        "        n_actions = int(self.eval_env.action_space.n)\n",
        "        assert isinstance(\n",
        "            self.eval_env.action_space, spaces.Discrete\n",
        "        ), \"FQI only support discrete actions\"\n",
        "\n",
        "        while total_episodes < n_simulations:\n",
        "            # Record video\n",
        "            if video_recorder is not None:\n",
        "                video_recorder.capture_frame()\n",
        "\n",
        "            ### YOUR CODE HERE\n",
        "\n",
        "            # Retrieve the q-values for the current observation\n",
        "            # you need to re-use `get_q_values()`\n",
        "            # Then select the action that maximizes the q-value for each state\n",
        "            # Do a step in the env using the selected action\n",
        "\n",
        "            # Retrieve the q-values for the current observation\n",
        "            q_values = get_q_values(self.current_model, obs.reshape(1, -1), n_actions)\n",
        "\n",
        "            # Select the action that maximizes the q-value for the current state\n",
        "            action = np.argmax(q_values)\n",
        "\n",
        "            # Do a step in the environment using the selected action\n",
        "            #next_obs, reward, terminated, truncated, _ = self.eval_env.step(action)\n",
        "            obs, reward, terminated, truncated, _ = self.eval_env.step(action)\n",
        "\n",
        "\n",
        "            ### END OF YOUR CODE\n",
        "\n",
        "            episode_reward += float(reward)\n",
        "\n",
        "            done = terminated or truncated\n",
        "            if done:\n",
        "                episode_returns.append(episode_reward)\n",
        "                episode_reward = 0.0\n",
        "                total_episodes += 1\n",
        "                obs, _ = self.eval_env.reset()\n",
        "            #else :\n",
        "             #   obs = next_obs  # Update the observation\n",
        "\n",
        "\n",
        "        if video_recorder is not None:\n",
        "            print(f\"Saving video to {video_recorder.path}\")\n",
        "            video_recorder.close()\n",
        "\n",
        "        print(\n",
        "            f\"Total reward = {np.mean(episode_returns):.2f} +/- {np.std(episode_returns):.2f}\"\n",
        "        )\n",
        "\n",
        "        return np.mean(episode_returns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d824b98-6360-4d4e-a3e2-584c0c36665e",
      "metadata": {
        "id": "5d824b98-6360-4d4e-a3e2-584c0c36665e"
      },
      "source": [
        "### Performing experiments\n",
        "\n",
        "First, let's define some constants:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "c16a4e16-e2a8-432f-885f-27fbe0f61f7c",
      "metadata": {
        "id": "c16a4e16-e2a8-432f-885f-27fbe0f61f7c"
      },
      "outputs": [],
      "source": [
        "from rlberry.envs import gym_make\n",
        "from rlberry.manager import ExperimentManager\n",
        "\n",
        "# Max number of iterations\n",
        "n_iterations = 20\n",
        "# How often do we evaluate the learned model\n",
        "eval_freq = 2\n",
        "# How many episodes to evaluate every eval-freq\n",
        "n_eval_episodes = 10\n",
        "# discount factor\n",
        "gamma = 0.99\n",
        "# Number of discrete actions\n",
        "n_actions = int(env.action_space.n)\n",
        "\n",
        "\n",
        "env_id = \"CartPole-v1\"  # Id of the environment\n",
        "env_ctor = gym_make  # constructor for the env\n",
        "env_kwargs = dict(id=env_id)  # give the id of the env inside the kwargs\n",
        "\n",
        "eval_env_kwargs = dict(id=env_id, render_mode=\"rgb_array\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeeaf39d-0a48-4c68-aa5b-7b734e7bcc7f",
      "metadata": {
        "id": "aeeaf39d-0a48-4c68-aa5b-7b734e7bcc7f"
      },
      "source": [
        "Now let's create an `ExperimentManager`, which is a class used to run experiments with specified agents and environments.\n",
        "\n",
        "The experiment manager spawns agents and environments for training and then once the agents are trained, it uses these agents and new environments to evaluate how well the agents perform. All of these steps can be done several times to assess stochasticity of agents and/or environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "7cbff0d8-eab0-4cec-847e-23bc1c509359",
      "metadata": {
        "id": "7cbff0d8-eab0-4cec-847e-23bc1c509359"
      },
      "outputs": [],
      "source": [
        "my_experiment = ExperimentManager(\n",
        "    Fitted_Q_Iteration,  # Agent Class\n",
        "    (env_ctor, env_kwargs),  # Environment as Tuple(constructor,kwargs)\n",
        "    init_kwargs=dict(\n",
        "        model_class=model_class,\n",
        "        n_steps_collection=50_000,\n",
        "        eval_freq=eval_freq,\n",
        "        n_eval_episodes=n_eval_episodes,\n",
        "        gamma=gamma,\n",
        "    ),\n",
        "    eval_env=(env_ctor, eval_env_kwargs),\n",
        "    fit_budget=int(n_iterations),  # Budget used to call our agent \"fit()\"\n",
        "    n_fit=1,  # Number of agent instances to fit.\n",
        "    agent_name=\"Agent_FQI_\" + env_id,  # Name of the agent\n",
        "    seed=42,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b83f248b-14d3-468e-a218-d1164740006c",
      "metadata": {
        "id": "b83f248b-14d3-468e-a218-d1164740006c"
      },
      "source": [
        "Use `fit()` to train an agent and then `eval_agents()` to evaluate the trained agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "594a49dc-8187-4b13-9dcc-cd49148673ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "594a49dc-8187-4b13-9dcc-cd49148673ca",
        "outputId": "81f34116-b676-4b59-e2e4-517972a0bf32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[38;21m[INFO] 10:59: Running ExperimentManager fit() for Agent_FQI_CartPole-v1 with n_fit = 1 and max_workers = None. \u001b[0m\n",
            "INFO:rlberry_logger:Running ExperimentManager fit() for Agent_FQI_CartPole-v1 with n_fit = 1 and max_workers = None.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter 2\n",
            "Score: 0.73\n",
            "Total reward = 22.20 +/- 9.89\n",
            "Iter 4\n",
            "Score: 0.86\n",
            "Total reward = 135.90 +/- 9.45\n",
            "Iter 6\n",
            "Score: 0.90\n",
            "Total reward = 157.80 +/- 27.95\n",
            "Iter 8\n",
            "Score: 0.92\n",
            "Total reward = 177.70 +/- 30.62\n",
            "Iter 10\n",
            "Score: 0.93\n",
            "Total reward = 173.60 +/- 27.33\n",
            "Iter 12\n",
            "Score: 0.93\n",
            "Total reward = 190.70 +/- 48.67\n",
            "Iter 14\n",
            "Score: 0.94\n",
            "Total reward = 337.20 +/- 58.65\n",
            "Iter 16\n",
            "Score: 0.94\n",
            "Total reward = 419.00 +/- 85.17\n",
            "Iter 18\n",
            "Score: 0.94\n",
            "Total reward = 361.90 +/- 100.73\n",
            "Iter 20\n",
            "Score: 0.94\n",
            "Total reward = 400.10 +/- 88.26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[38;21m[INFO] 11:00: ... trained! \u001b[0m\n",
            "INFO:rlberry_logger:... trained!\n",
            "\u001b[38;21m[INFO] 11:00: Saved ExperimentManager(Agent_FQI_CartPole-v1) using pickle. \u001b[0m\n",
            "INFO:rlberry_logger:Saved ExperimentManager(Agent_FQI_CartPole-v1) using pickle.\n",
            "\u001b[38;21m[INFO] 11:00: The ExperimentManager was saved in : 'rlberry_data/temp/manager_data/Agent_FQI_CartPole-v1_2024-01-12_10-59-20_0be04f64/manager_obj.pickle' \u001b[0m\n",
            "INFO:rlberry_logger:The ExperimentManager was saved in : 'rlberry_data/temp/manager_data/Agent_FQI_CartPole-v1_2024-01-12_10-59-20_0be04f64/manager_obj.pickle'\n"
          ]
        }
      ],
      "source": [
        "my_experiment.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3477740-bfe4-4e0b-8a5d-cd0206786c8b",
      "metadata": {
        "id": "e3477740-bfe4-4e0b-8a5d-cd0206786c8b"
      },
      "source": [
        "### Record a video of the trained agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "da8d90cc-2d77-4682-a97c-a3dacd081f38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da8d90cc-2d77-4682-a97c-a3dacd081f38",
        "outputId": "ed58ed74-688b-47bb-9276-4a489f492d9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO] Evaluation:INFO:rlberry_logger:[INFO] Evaluation:\n",
            "Warning: n_simulations parameter in eval_kwargs is being overwritten with 1.INFO:rlberry_logger:Warning: n_simulations parameter in eval_kwargs is being overwritten with 1.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving video to ./logs/videos/FQI_CartPole-v1.mp4\n",
            "Moviepy - Building video ./logs/videos/FQI_CartPole-v1.mp4.\n",
            "Moviepy - Writing video ./logs/videos/FQI_CartPole-v1.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ".INFO:rlberry_logger:.\n",
            "Warning: n_simulations parameter in eval_kwargs is being overwritten with 1.INFO:rlberry_logger:Warning: n_simulations parameter in eval_kwargs is being overwritten with 1.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready ./logs/videos/FQI_CartPole-v1.mp4\n",
            "Total reward = 382.00 +/- 0.00\n",
            "Saving video to ./logs/videos/FQI_CartPole-v1.mp4\n",
            "Moviepy - Building video ./logs/videos/FQI_CartPole-v1.mp4.\n",
            "Moviepy - Writing video ./logs/videos/FQI_CartPole-v1.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ".INFO:rlberry_logger:.\n",
            "  Evaluation finished \n",
            "INFO:rlberry_logger:  Evaluation finished \n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready ./logs/videos/FQI_CartPole-v1.mp4\n",
            "Total reward = 500.00 +/- 0.00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[382.0, 500.0]"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "video_name = f\"FQI_{env_id}\"\n",
        "n_eval_episodes = 3\n",
        "my_experiment.eval_agents(\n",
        "    eval_kwargs=dict(n_simulations=n_eval_episodes, video_name=video_name)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "e84c6d08",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e84c6d08",
        "outputId": "51fabd97-2a86-4565-e511-f0c046648103"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import base64\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "\n",
        "def show_videos(video_path: str = \"\", prefix: str = \"\") -> None:\n",
        "    \"\"\"\n",
        "    Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "    :param video_path: Path to the folder containing videos\n",
        "    :param prefix: Filter the video, showing only the only starting with this prefix\n",
        "    \"\"\"\n",
        "    html = []\n",
        "    for mp4 in Path(video_path).glob(f\"{prefix}*.mp4\"):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append(\n",
        "            \"\"\"<video alt=\"{}\" autoplay\n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>\"\"\".format(\n",
        "                mp4, video_b64.decode(\"ascii\")\n",
        "            )\n",
        "        )\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "bfc66910-de41-4622-9811-96addf8ba8d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "bfc66910-de41-4622-9811-96addf8ba8d3",
        "outputId": "455dd9cd-e81f-46d5-be1d-83f332a4827f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FQI agent on CartPole-v1 after 20 iterations:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<video alt=\"logs/videos/FQI_CartPole-v1.mp4\" autoplay\n",
              "                    loop controls style=\"height: 400px;\">\n",
              "                    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "                </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(f\"FQI agent on {env_id} after {n_iterations} iterations:\")\n",
        "show_videos(\"./logs/videos/\", prefix=video_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69a60230-6477-4318-8d60-10f6eada6064",
      "metadata": {
        "id": "69a60230-6477-4318-8d60-10f6eada6064"
      },
      "source": [
        "### Going further (optional)\n",
        "\n",
        "- play with different models, and with their hyperparameters\n",
        "- play with the discount factor\n",
        "- play with the number of data collected/used\n",
        "- combine data from random policy with data from trained model\n",
        "- Use a neural network as the regression model (Scikit-learn has a class for simple fully connected neural networks)\n",
        "- Implement DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40b8a44f-d48c-4a9d-8ed4-968c1ffb9948",
      "metadata": {
        "id": "40b8a44f-d48c-4a9d-8ed4-968c1ffb9948"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "What we have seen in this notebook:\n",
        "- collecting data using a random agent in a gym environment\n",
        "- predicting q-values using a regression model\n",
        "- the fitted q-iteration (FQI) algorithm to learn from an offline dataset"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
